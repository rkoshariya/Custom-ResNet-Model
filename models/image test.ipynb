{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This script is used for generating reduction.onnx model. For this first I have written custom_op_export() method. The first part is simply\n",
    "evaluating the images for cosine similarities and producing the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique images are:\n",
      "1\n",
      "11\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "from numpy import dtype\n",
    "import timm\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "torch.ops.load_library(\"op.pyd\")\n",
    "\n",
    "from prepare_input import prepare\n",
    "\n",
    "from render import show_images\n",
    "\n",
    "model = timm.create_model('resnet18', pretrained=True)\n",
    "model.eval();\n",
    "\n",
    "current_path = os.getcwd()\n",
    "\n",
    "folder = os.path.join(current_path, 'Challenge_images')\n",
    "imgs = []\n",
    "\n",
    "    # loop us implemented to read the images one by one from the loop.\n",
    "    # listdir return a list containing the names of the entries\n",
    "    # in the directory.\n",
    "for filename in os.listdir(folder):\n",
    "    img = cv2.imread((os.path.join(folder, filename)))\n",
    "    img = cv2.resize(img, (416, 416),\n",
    "               interpolation = cv2.INTER_NEAREST)\n",
    "    imgs.append(img)\n",
    "\n",
    "inps = [prepare(img, model.default_cfg['mean'], model.default_cfg['std'])\n",
    "        for img in imgs]\n",
    "\n",
    "return_nodes = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "feat_ext = create_feature_extractor(model, return_nodes=return_nodes)\n",
    "tensor_result =torch.zeros(50,512)\n",
    "index = 0\n",
    "for i in inps:\n",
    "    with torch.no_grad():\n",
    "        out = feat_ext(i)\n",
    "    \n",
    "    m = nn.AdaptiveAvgPool2d((1,1))\n",
    "    n = nn.AdaptiveAvgPool2d((1,1))\n",
    "    o = nn.AdaptiveAvgPool2d((1,1))\n",
    "    p = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "    layer1_out = m(out['layer1']).view(1,-1)\n",
    "    layer2_out = n(out['layer2']).view(1,-1)\n",
    "    layer3_out = m(out['layer3']).view(1,-1)\n",
    "    layer4_out = m(out['layer4']).view(1,-1)\n",
    "\n",
    "    x = torch.ops.custom_namespace.op(layer1_out,layer2_out,layer3_out,layer4_out)\n",
    "    tensor_result[index] = x\n",
    "    index = index + 1\n",
    "image_list =[]\n",
    "for i in range(0,50):\n",
    "    count = 0\n",
    "    for j in range(0,50):\n",
    "        cos = torch.nn.CosineSimilarity(dim=0 , eps = 1e-6)\n",
    "        output = cos(tensor_result[i],tensor_result[j])\n",
    "        if(output>=0.75):\n",
    "            count = count + 1\n",
    "        else:\n",
    "            pass\n",
    "    if count <= 1:\n",
    "        image_list.append(i)\n",
    "    \n",
    "print(\"Unique images are:\")\n",
    "for x in image_list:\n",
    "    print(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import torch and torch.onnx for onnx runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.onnx\n",
    "import torch._C._onnx as _C_onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the custom operator with ONNX runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_custom_op():\n",
    "    def my_op(g, layerOne, layerTwo, layerThree, layerFour):\n",
    "        return g.op(\"mydomain::testop\", layerOne, layerTwo, layerThree, layerFour)\n",
    "\n",
    "    from torch.onnx import register_custom_op_symbolic\n",
    "\n",
    "    register_custom_op_symbolic(\"custom_namespace::op\", my_op, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export_custom_op() method for exporting the model in .onnx format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import ScriptModule\n",
    "\n",
    "\n",
    "def export_custom_op():\n",
    "      layerOne = torch.randn(1,64)\n",
    "      layerTwo = torch.randn(1,128)\n",
    "      layerThree = torch.randn(1,256)\n",
    "      layerFour = torch.randn(1,512)\n",
    "      class CustomModel(torch.nn.Module):\n",
    "            def __init__(self):\n",
    "                  super(CustomModel, self).__init__()\n",
    "                  model = timm.create_model('resnet18', pretrained=True)\n",
    "                  model.eval();\n",
    "                  current_path = os.getcwd()\n",
    "\n",
    "                  folder = os.path.join(current_path, 'Challenge_images')\n",
    "                  imgs = []\n",
    "\n",
    "    # loop us implemented to read the images one by one from the loop.\n",
    "    # listdir return a list containing the names of the entries\n",
    "    # in the directory.\n",
    "                  for filename in os.listdir(folder):\n",
    "                        img = cv2.imread((os.path.join(folder, filename)))\n",
    "                        img = cv2.resize(img, (416, 416),\n",
    "                                          interpolation = cv2.INTER_NEAREST)\n",
    "                        imgs.append(img)\n",
    "\n",
    "                  inps = [prepare(img, model.default_cfg['mean'], model.default_cfg['std'])\n",
    "                              for img in imgs]\n",
    "\n",
    "                  return_nodes = ['layer1', 'layer2', 'layer3', 'layer4']\n",
    "\n",
    "                  feat_ext = create_feature_extractor(model, return_nodes=return_nodes)\n",
    "\n",
    "                  tensor_result =torch.zeros(50,512)\n",
    "                  index = 0\n",
    "                  for i in inps:\n",
    "                        with torch.no_grad():\n",
    "                              out = feat_ext(i)\n",
    "    \n",
    "                  m = nn.AdaptiveAvgPool2d((1,1))\n",
    "                  n = nn.AdaptiveAvgPool2d((1,1))\n",
    "                  o = nn.AdaptiveAvgPool2d((1,1))\n",
    "                  p = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "                  layer1_out = m(out['layer1']).view(1,-1)\n",
    "                  layer2_out = n(out['layer2']).view(1,-1)\n",
    "                  layer3_out = m(out['layer3']).view(1,-1)\n",
    "                  layer4_out = m(out['layer4']).view(1,-1)\n",
    "                  torch.ops.custom_namespace.op(layerOne, layerTwo, layerThree, layerFour)\n",
    "            def forward(self ,x):\n",
    "                 return None \n",
    "                  \n",
    "      \n",
    "      custom_model = CustomModel()\n",
    "\n",
    "      \n",
    "      torch.onnx.export(custom_model,args=None,f=\"reduction.onnx\",\n",
    "                      opset_version=15)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ops.load_library(\"op.pyd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_custom_op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_custom_op()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ada_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5528979543291f4ff7dbe8d869c4bdc160cc5d7412ea2a3ffbbbc9b589fee580"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
